{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('BlackFriday.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#ONEHOTENCODER\\nonehot = OneHotEncoder(categorical_features=[2, 4])\\nX = onehot.fit_transform(X).toarray()\\n\\nonehot = OneHotEncoder(categorical_features=[2])\\ndataset_easy2 = onehot.fit_transform(dataset_easy2).toarray()\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CATEGORIA DE CADA PRODUTO\n",
    "dataset_categorical = dataset[['Product_ID', 'Product_Category_1', 'Product_Category_2', 'Purchase']].copy()\n",
    "\n",
    "#PREENCHENDO NULOS DA CATEGORIA 2\n",
    "produto2_random = pd.DataFrame(dataset_categorical['Product_Category_2'].value_counts(1))\n",
    "produto2_random = produto2_random.reset_index()\n",
    "dataset_categorical['Product_Category_2'].fillna(np.random.choice(produto2_random.index, p=produto2_random.Product_Category_2), inplace=True)\n",
    "\n",
    "#DIVIDINDO VARIÁVEIS POR CATEGORIA\n",
    "categorical1 = dataset_categorical['Product_Category_1']\n",
    "categorical2 = dataset_categorical['Product_Category_2']\n",
    "\n",
    "\n",
    "#STANDARD SCALER\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "dataset_easy = dataset[['User_ID', 'Gender', 'Age', 'Occupation', 'City_Category','Stay_In_Current_City_Years', 'Marital_Status', 'Purchase']].copy()\n",
    "\n",
    "#LABEL ENCODER\n",
    "labelencoder = LabelEncoder()\n",
    "dataset_easy['Gender'] = labelencoder.fit_transform(dataset_easy['Gender'])\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "dataset_easy['Age'] = labelencoder.fit_transform(dataset_easy['Age'])\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "dataset_easy['Occupation'] = labelencoder.fit_transform(dataset_easy['Occupation'])\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "dataset_easy['City_Category'] = labelencoder.fit_transform(dataset_easy['City_Category'])\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "dataset_easy['Stay_In_Current_City_Years'] = labelencoder.fit_transform(dataset_easy['Stay_In_Current_City_Years'])\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "dataset_easy['Marital_Status'] = labelencoder.fit_transform(dataset_easy['Marital_Status'])\n",
    "\n",
    "dataset_easy2 = dataset_easy[['Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']].copy()\n",
    "\n",
    "\"\"\"\n",
    "#QUAIS AS MELHORES VARIÁVEIS PARA PREDIZER A CATEGORIA 1?\n",
    "from info_gain import info_gain\n",
    "Gender  = info_gain.info_gain(dataset_easy2['Gender'], categorical1)\n",
    "Age  = info_gain.info_gain(dataset_easy2['Age'], categorical1)\n",
    "Occupation  = info_gain.info_gain(dataset_easy2['Occupation'], categorical1)\n",
    "City_Category  = info_gain.info_gain(dataset_easy2['City_Category'], categorical1)\n",
    "Stay_In_Current_City_Years  = info_gain.info_gain(dataset_easy2['Stay_In_Current_City_Years'], categorical1)\n",
    "Marital_Status  = info_gain.info_gain(dataset_easy2['Marital_Status'], categorical1)\n",
    "print('Ganho de Informação\\n', Gender, Age, Occupation, City_Category, Stay_In_Current_City_Years, Marital_Status)\n",
    "\n",
    "#Gender, Age e Occupation são os melhores preditores para prever categorical1\n",
    "dataset_easy2 = dataset_easy2[['Gender', 'Age', 'Occupation']].copy()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "dataset_easy = dataset_easy.groupby('User_ID')['Gender', 'Age', 'Occupation', 'City_Category',\n",
    "       'Stay_In_Current_City_Years', 'Marital_Status', 'Purchase'].mean()\n",
    "\n",
    "X = dataset_easy[['Gender', 'Age', 'Occupation', 'City_Category', 'Marital_Status']].copy()\n",
    "\n",
    "y = np.array(dataset_easy['Purchase'].copy())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#ONEHOTENCODER\n",
    "onehot = OneHotEncoder(categorical_features=[2, 4])\n",
    "X = onehot.fit_transform(X).toarray()\n",
    "\n",
    "onehot = OneHotEncoder(categorical_features=[2])\n",
    "dataset_easy2 = onehot.fit_transform(dataset_easy2).toarray()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0     740\n",
       "0.0     688\n",
       "7.0     669\n",
       "1.0     517\n",
       "17.0    491\n",
       "12.0    376\n",
       "14.0    294\n",
       "20.0    273\n",
       "2.0     256\n",
       "16.0    235\n",
       "6.0     228\n",
       "10.0    192\n",
       "3.0     170\n",
       "15.0    140\n",
       "13.0    140\n",
       "11.0    128\n",
       "5.0     111\n",
       "9.0      88\n",
       "19.0     71\n",
       "18.0     67\n",
       "8.0      17\n",
       "Name: Occupation, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bruno\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\users\\bruno\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "c:\\users\\bruno\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\users\\bruno\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#ONEHOTENCODER\n",
    "onehot = OneHotEncoder(categorical_features=[3])\n",
    "X = onehot.fit_transform(X).toarray()\n",
    "\n",
    "onehot = OneHotEncoder(categorical_features=[3])\n",
    "dataset_easy2 = onehot.fit_transform(dataset_easy2).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recomendando Categoria 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "    Produto  Probabilidade\n",
      "0       4.0          35.40\n",
      "1       5.0          18.15\n",
      "2       3.0          12.03\n",
      "3       8.0          11.41\n",
      "4       9.0           6.59\n",
      "5      15.0           5.88\n",
      "6      17.0           3.84\n",
      "7      16.0           2.35\n",
      "8      14.0           2.13\n",
      "9       6.0           0.82\n",
      "10     18.0           0.78\n",
      "11     12.0           0.63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(len(dataset_categorical)):\\n    vetor.append(dataset_categorical['Product_Category_1'][dataset_categorical['Product_Category_1']==1])\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Relação em porcentagem entre Categoria 1 e Categoria 2\n",
    "\"\"\"\n",
    "\n",
    "vetor = []\n",
    "\n",
    "for i in range(1, len((dataset_categorical['Product_Category_1'].unique()))):\n",
    "\n",
    "    k = dataset_categorical['Product_Category_2'][dataset_categorical['Product_Category_1']==i]\n",
    "    k=k.value_counts(1)\n",
    "\n",
    "    vetor.append([i, k.index, k.values])\n",
    "\n",
    "\n",
    "insere = int(input())\n",
    "\n",
    "for i in range(len(vetor)):\n",
    "    if(vetor[i][0]==insere):\n",
    "        df = pd.DataFrame({'Produto':vetor[i][1], 'Probabilidade':(vetor[i][2]*100).round(2)})\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.886\n",
      "Model:                            OLS   Adj. R-squared:                  0.886\n",
      "Method:                 Least Squares   F-statistic:                     9148.\n",
      "Date:                Fri, 06 Sep 2019   Prob (F-statistic):               0.00\n",
      "Time:                        15:36:42   Log-Likelihood:                -56186.\n",
      "No. Observations:                5891   AIC:                         1.124e+05\n",
      "Df Residuals:                    5886   BIC:                         1.124e+05\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Gender          3661.2867     87.489     41.849      0.000    3489.776    3832.797\n",
      "Age              862.2532     28.100     30.685      0.000     807.167     917.340\n",
      "Occupation       128.7026      6.758     19.046      0.000     115.455     141.950\n",
      "City_Category   2008.0685     50.179     40.018      0.000    1909.700    2106.437\n",
      "Marital_Status   514.4214     93.422      5.506      0.000     331.279     697.564\n",
      "==============================================================================\n",
      "Omnibus:                        3.523   Durbin-Watson:                   1.832\n",
      "Prob(Omnibus):                  0.172   Jarque-Bera (JB):                3.476\n",
      "Skew:                           0.057   Prob(JB):                        0.176\n",
      "Kurtosis:                       3.033   Cond. No.                         22.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Teste de Significância\n",
    "OLS = sm.OLS(exog=X, endog=y).fit()\n",
    "print(OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=5891, step=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "y.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14495.768602421325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "X = X.reset_index(drop=True)\n",
    "#REMOVENDO OUTLIERS\n",
    "max = y.quantile(0.75)+(y.quantile(0.75)-y.quantile(0.25))*1.5\n",
    "min = y.quantile(0.25)+(y.quantile(0.75)-y.quantile(0.25))*1.5\n",
    "\n",
    "print(max)\n",
    "\n",
    "for i in range(len(y)):\n",
    "       if((y[i]>max) or (y[i]<min)):\n",
    "            y = y.drop(i, axis=0)\n",
    "            X = X.drop(i, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE/mean(y_test) 710.1734813391115\n"
     ]
    }
   ],
   "source": [
    "#DIVIDINDO O DATASET\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#ADABOOST\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada = AdaBoostRegressor(learning_rate=0.1, loss='linear', n_estimators=600)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ada = ada.predict(X_test)\n",
    "\n",
    "#MÉTRICAS\n",
    "\n",
    "print('RMSE', np.sqrt(mean_squared_error(y_test, y_pred_ada)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
